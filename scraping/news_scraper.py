# scraping/news_scraper.py
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import urllib.parse

class NewsScraper:
    def __init__(self):
        # Usamos Google News RSS especÃ­fico para PerÃº (geo=PE) y espaÃ±ol (hl=es-419)
        self.base_url = "https://news.google.com/rss/search?q={query}+when:7d&hl=es-419&gl=PE&ceid=PE:es-419"

    def analizar_impacto(self, texto):
        """
        Analiza el tÃ­tulo de la noticia para determinar la alerta.
        Retorna: (Nivel de Alerta, Mensaje)
        """
        texto = texto.lower()
        
        # DICCIONARIO DE PALABRAS CLAVE
        palabras_subida = ["sube", "alza", "incremento", "caro", "dispara", "elevado"]
        palabras_bajada = ["baja", "cae", "barato", "desciende", "oferta", "menor precio"]
        palabras_riesgo = ["escasez", "desabastecimiento", "paro", "bloqueo", "huelga", "fenÃ³meno", "lluvias", "sequÃ­a", "crisis"]

        # 1. Detectar SUBIDA confirmada
        if any(p in texto for p in palabras_subida):
            return "ðŸ”´ ALTA", "Â¡ALERTA! El precio estÃ¡ subiendo."
            
        # 2. Detectar RIESGO (Posible subida)
        if any(p in texto for p in palabras_riesgo):
            return "ðŸŸ  MEDIA", "PRECAUCIÃ“N: Riesgo de escasez o subida (Clima/Conflictos)."
            
        # 3. Detectar BAJADA
        if any(p in texto for p in palabras_bajada):
            return "ðŸŸ¢ BUENA", "Oportunidad: El precio podrÃ­a bajar."

        return "âšª NEUTRA", "Noticia informativa."

    def buscar_noticias(self, producto):
        """
        Busca noticias sobre un producto especÃ­fico (ej: 'Arroz precio').
        """
        # Codificamos la bÃºsqueda para URL (ej: 'precio arroz peru')
        busqueda = urllib.parse.quote(f"precio {producto} peru")
        url_final = self.base_url.format(query=busqueda)
        
        try:
            response = requests.get(url_final, timeout=10)
            # Parseamos el XML del RSS
            soup = BeautifulSoup(response.content, features='xml')
            items = soup.find_all('item')
            
            noticias_relevantes = []
            
            # Analizamos las 3 noticias mÃ¡s recientes
            for item in items[:3]:
                titulo = item.title.text
                link = item.link.text
                fecha = item.pubDate.text
                
                nivel, mensaje = self.analizar_impacto(titulo)
                
                # Solo guardamos si NO es neutra (para no llenar de ruido), 
                # o si tÃº quieres ver todo, quita el 'if nivel != ...'
                if nivel != "âšª NEUTRA":
                    noticias_relevantes.append({
                        "producto": producto,
                        "titulo": titulo,
                        "nivel": nivel,
                        "mensaje": mensaje,
                        "url": link,
                        "fecha": fecha
                    })
            
            return noticias_relevantes

        except Exception as e:
            print(f"Error buscando noticias de {producto}: {e}")
            return []